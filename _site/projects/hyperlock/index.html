<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Hyperlock | Caixunshiren</title>
    <meta name="author" content="Jack Xun Cai" />
    <meta name="description" content="Hardware cryptography algorithm I invented using memristor circuit." />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üêñ</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/projects/hyperlock/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/">Caixunshiren</a>

          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/about/">About</a>
              </li>
              <!-- Misc -->
              <li class="nav-item ">
                <a class="nav-link" href="/misc/">Misc</a>
              </li>

              <!-- Projects -->
              <li class="nav-item active">
                <a class="nav-link" href="/projects/">Projects<span class="sr-only">(current)</span></a>
              </li>

              <!-- CV -->
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">Resume</a>
              </li>

              <!-- Publications -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
<div class="post">
  <header class="post-header">
          <h1 class="post-title" style="font: size 20%;">
              &gt;. 
              <span class="font-weight-bold" id="typewriter"></span>
          </h1>
          <br>
          <p class="post-description">Hardware cryptography algorithm I invented using memristor circuit.</p>
  </header>

  <article>
    <h1 id="hyperlock--in-memory-hyperdimensional-encryption-in-memristor-crossbar-array">HyperLock:  In-Memory Hyperdimensional Encryption in Memristor Crossbar Array</h1>
<p>Novel cryptography architecture based on memristor crossbar array, binary hypervectors, and neural network.</p>

<p><a href="https://github.com/caixunshiren/hyperlock/blob/main/HYPERLOCK_blind_peer_reveiw_ver.pdf" target="_blank" rel="noopener noreferrer">paper here</a></p>
<h1 id="abstract">Abstract</h1>
<p><strong>Abstract</strong>‚ÄîWe present a novel cryptography architecture based on memristor crossbar array, binary hypervectors, and neural network. Utilizing the stochastic and unclonable nature of memristor crossbar and error tolerance of binary hypervectors and neural network, implementation of the algorithm on memristor crossbar simulation is made possible. We demonstrate that with increasing dimension of the binary hypervectors, the nonidealities in memristor circuit can be effectively controlled. At thefine level of controlled crossbar non-ideality, noise from memristor circuit can be used to encrypt data while being sufficiently interpretable by neural network for decryption. We applied our algorithm on image cryptography for proof of concept, and to text en/decryption with 100% decryption accuracy despite of crossbar noises. Our work shows the potential and feasibility of using memristor crossbar as an unclonable stochastic encoder unit of cryptography on top of its existing functionality as a vector matrix multiplication acceleration device.</p>

<p><img src="https://raw.githubusercontent.com/caixunshiren/HyperLock/main/figure/paper/Figure%201.png" alt="drawing" width="750">
    <strong>Fig. 1.</strong>  Vector-matrix multiplication (VMM) over the memristor crossbar. 3D crossbar array has been displayed with input voltage and bit-line currents.</p>

<h1 id="introduction">Introduction</h1>
<p>Memristors are non-volatile, configurable memory devices [1-2]. Their ability to permanently store variable conductance information makes them good candidates to build analog vector matrix multiplications (VMM) crossbar accelerators for in-memory computing. The crossbar performs VMM in O(1) and overcomes von Neumann bottleneck with in-memory computing [3], which enables many edge computing applications in machine learning such as CNN [6], LSTM [7] and neurmorphic computing [9]. However, despite their high efficiency, low footprint, and low power consumption [9-11], memristor crossbar suffer non-ideality issues such as sneak path current, device variability, stuck conductance, and cycle-to-cycle variability [12-15]. In some literature, nonideality and behaviours of memristors are studied and their stochasiticity are exploit for hardware security applications [15] such as physical unclonable functions (PUFs) [16-18] and chaotic circuits [19-20]. Despite algorithms proposed in these studies covers from generating stochastic sequences for hardware verification to public and private key cryptography, none of which have touched on using memristor crossbar‚Äôs VMM operation to encrypt the data directly. In in-memory hyperdimensional encryption, we investigate the feasibility of using memristor crossbar‚Äôs stochastic VMM operation for data encryption. Encrypting data directly with memristor crossbar poses a challenge for decryption because of the cycle to cycle variability can result in inconsistent cipher text for the same input. On the other hand, such randomness can be beneficial as it prevents repetitiveness of the encrypted text. In-memory hyperdimensional computing concept proposed by IBM [4] demonstrates the robustness of binary hypervectors against memrisor crossbar non-ideality. Such discovery leads to the inspiration of this work: to utilize binary hypervectors encryption to control the impact of noise generated by memristor crossbar, then train a shallow neural network for decryption. We demonstrate in simulation experiments: 1) the proof of concept on image cryptography, and 2) in text en/decryption to show that at a fine level of noise, the cipher text is near 100% decryptable by the neural network while being unique for each pass. Using memristor crossbar for this algorithm has a few benefits. First, the cost of VMM operation is low due to in-memory computing. Secondly, the algorithm can benefit from the intrinsic stochasticity of the memristor crossbar without the need of adding artificial noises. In the end, noises generated by crossbar provides additional security levels, and exact properties of the crossbar is unobtainable and unclonable by attackers. Power and time complexity of memristor crossbar are compared with CMOS digital implementation.</p>

<h1 id="preliminaries">Preliminaries</h1>
<h3 id="memristor-crossbar-arrays">Memristor Crossbar Arrays</h3>
<p>A typical structure of a crossbar is shown in Fig. 1, where memristors are programmed and sandwiched between the word lines and the bit-lines. When analog voltage vectors are applied through the word-lines, memristors act as multiplication units according to Ohm‚Äôs law (i.e. I = V G), and the current output from the memristors are then accumulated through the bit-lines. Despite its ideal functionalities, real implementation of the crossbar often comes with non-ideality [12-15] that causes errors in the output current vectors.</p>

<h3 id="binary-hypervectors">Binary Hypervectors</h3>
<p>Binary hypervectors (BHV), first introduced by Kanerva [5] in his model of hyperdimensional (HD) computing, are binary vectors with dimensions in the orders of thousands. Unlike traditional real-valued vectors that are optimized for space, BHVs are optimized for robustness. In BHV, information is distributed evenly across all entries. Such representation provides resilience against noise, non-ideality, and low resolution in computer hardware as randomly flipping one bit of information has almost no impact on the vector‚Äôs representation [22]. Since the information is evenly spread, BHV can be more robust when its dimension is increased. Real valued vectors, on the other hand, are prone to these noises, as failure at a critical bit can change the vector‚Äôs representation significantly. Fig. 2(a) contrast the two vectors.</p>

<p><img src="https://raw.githubusercontent.com/caixunshiren/HyperLock/main/figure/paper/Figure%202.png" alt="drawing" width="750">
    <strong>Fig. 2.</strong>  (a) Binary hypervector representation versus real vector representation. (b) Proposed model architecture schematic for in-memory hyperdimensional encryption. (c) Image encryption and decryption implementation.</p>

<h1 id="proposed-model-architecture">Proposed Model Architecture</h1>
<p>Our proposed architecture (Fig. 2(b)) consists of a hyperdimensional stochastic encoder that encrypts the ordinary real value vectors into binary hypervectors, and a multi-layer perceptron (MLP) decoder that reconstructs the original vector.</p>

<h3 id="hyperdimensional-stochastic-encoder">Hyperdimensional Stochastic Encoder</h3>
<p>The stochastic encoder is characterized by Equation (1), where W_encoder is a tall, randomly initialized matrix thatlinearly transforms the original low dimensional input vector x into a hypervector, f_noise(t,W_encoder,x) is some noise function that depends on time t, W_encoder, and x, and H is a binarization function defined by Equation (2), where epsilon is a hyperparameter. The result, x_bhv, is an encrypted binary hypervector.</p>
<p align="center">
  <img width="600" src="https:/raw.githubusercontent.com/caixunshiren/HyperLock/main/figure/paper/eq12.png" alt="Equation (1) &amp; (2)">
</p>
<p>The above formulation models the VMM of an intrinsic memristor crossbar array followed by a threshold. The randomly initialized matrix Wencoder can be thought as an untuned memristor crossbar, and the noise function fnoise(t;Wencoder; x) are the crossbar non-idealities which depend on the crossbar conductance (finite conductance states and conductance variability), input voltage vectors (e.g. sneak path current), and time (cycle to cycle variability).
The intuition behind a hyperdimensional stochastic encoder is that the VMM operation will create hypervectors, evenly distributes input vector‚Äôs information across all entries. As a result, information at each entry can be represented by binary states. On the other hand, impact on performance from noise reduces as the dimension of the BHV gets larger. By altering the output dimension of the stochastic encoder, we control the level of noise presented in the encrypted BHV.</p>

<h3 id="neural-network-decoder">Neural Network Decoder</h3>
<p>Encrypted BHV is fed into a fully connected neural network, dimension reduced by the weighted edges to reconstruct the original input vector. Weights of the neural network can be obtained through supervised learning.</p>

<h1 id="image-encryption">Image Encryption</h1>
<p>We first apply our proposed model for image en/decryption (Fig. 2(c)) to verify the assumptions we had in our formulation. We create a naive simulation on PyTorch, where the stochastic encoder is implemented by Equation (3).</p>
<p align="center">
  <img width="600" src="https:/raw.githubusercontent.com/caixunshiren/HyperLock/main/figure/paper/eq3.png" alt="Equation (3)">
</p>
<p>W_encoder is a fixed matrix randomly generated by PyTorch‚Äôs uniform initialization function in the interval (-2,2) and W_Gaussian is a Gaussian noise matrix generated by PyTorch‚Äôs normal distribution function at each pass. The input vector x is the flattened image vector. After encoded by Equation (3), the encrypted BHV is fed into a single layer MLP to reconstruct the original image. During training, we used root mean square error as cost function and stochastic gradient descent (SGD) to train the model until the validation loss stabilizes. We present en/decryption result in Fig. 3.</p>

<h3 id="dataset-and-benchmark-model">Dataset and Benchmark model</h3>
<p>We trained the model on MNIST and CIFAR-10 image classification dataset respectively. MNIST consists of 60K 28 x 28 black and white images of handwritten digits from 0 - 9, and CIFAR-10 consists of 60K 32 x 32 color images representing 10 classes of objects. Instead of performing classification, we trained the MLP to reconstruct these images. 
We trained a benchmark model where Wencoder in Equation (3) is a square matrix which does not expand the input vector x to hyperdimension, and we got rid of the threshold function. Ideally, the MLP decoder will learn the inverse of Wencoder when noise is not presented, achieving little to no image reconstruction noise for decryption in perfect scenario.</p>

<h3 id="simulation-results">Simulation Results</h3>
<p>We show, in Fig. 3(a-c), the raw encryption result along with the change in pixel distribution and correlation of encrypting a 150 x 150 pixels Girl with a Pearl Earring image using our method. We show no obvious correlations between pixels. In Fig. 3(d), we demonstrate the positive correlation between dimension expansion and reconstructed image quality and, in Fig. 3(e), the robustness of BHV model against noise compared to the benchmark model. Reconstructed digit still remains legible even when the Gaussian noise standard deviation is equal to Wencoder‚Äôs initialization range (-2,2).</p>

<p><img src="https://raw.githubusercontent.com/caixunshiren/HyperLock/main/figure/paper/Figure%203.png" alt="drawing" width="750">
    <strong>Fig. 3.</strong>  Image encryption and decryption results. Image encryption result is on a 150 x 150 pixels Girl with a Pearl Earring image. (a) Raw image at three stages of encryption: before, after dimension expansion, and after threshold. (b) Pixel correlation at the three stages. (c) Adjacent pixel correlation at the three stages. Note that pixel correlation at the third stage is represented by a bar graph due to there are only 4 adjacent pixel combinations, namely: 0 - 0, 0 - 1, 1 - 0, 1 - 1. (d) Image decryption results: Reconstructed images at different level of dimension multiplier (the factor in which the input image vector dimension is expanded) in the stochastic encoding. (e) Reconstructed MNIST images at different standard deviations of Gaussian noise.</p>

<h1 id="text-encryption">Text Encryption</h1>
<p>In this section, we generalize our proposed model to a text en/decryption model. The proposed model for this application is shown in Fig. 4(a).</p>

<h3 id="model-algorithm-dataset-and-simulation-setup">Model Algorithm, Dataset and Simulation Setup</h3>
<p>The model is described by Algorithm 1. New model can be generated without new crossbar simply by regenerating secret vectors and run Train(). The dataset used in simulations are characters of 94 classes, corresponding to ASCII 32 to 126. Our training, validation, and test sets consist of 100K, 100K, and 10K of randomly generated characters from the 94 classes, respectively. We tested the above algorithm on a memristor crossbar array simulation based on PyTorch. Conductance variability is modeled based on Gaussian distribution and random stuck on/off memristors. Samples of crossbar hyperparameters are presented in Table 1 along with the test set decryption accuracy.</p>

<p align="center">
  <img width="600" src="https:/raw.githubusercontent.com/caixunshiren/HyperLock/main/figure/paper/alg1.png" alt="Equation (3)">
</p>

<p align="center">
  <img width="800" src="https:/raw.githubusercontent.com/caixunshiren/HyperLock/main/figure/paper/table1.png" alt="Equation (3)">
</p>

<h1 id="experimental-results">Experimental Results</h1>
<p>We show the encrypted letters at different levels of crossbar noise in Fig. 4(b), with their corresponding decryption accuracy. Non-ideality within the memristor crossbar array makes the encoded BHV different at each pass, thereby ensuring the security of the encrypted text. In Fig. 4(c), we show the decryption performance on a crossbar with, 0.05 P_on and 0.05 P_off, at various levels of dimension multipliers and conductance variability. A model is considered ‚Äùgood‚Äù if the result decryption accuracy is at least 99.9% on the test set. In Fig. 4(d), we show the decryption accuracy curves of various models. We simulated energy and time complexity on analog Ag:Si memristor crossbar and digital SRAM [23] at different crossbar sizes for the stochastic encoder with NeuroSim MLP [24]. Fig 4(e-f) compares the result. The Ag:Si memristor consumes 30X less energy than digital SRAM implementation while having consistent read latency at increasing VMM scale. In addition, digital implementation does not have the security advantage from crossbar non-ideality.</p>

<p><img src="https://raw.githubusercontent.com/caixunshiren/HyperLock/main/figure/paper/Figure%204.png" alt="drawing" width="750">
    <strong>Fig. 4.</strong>  Application for Text Decryption and Encryption results.(a) Text en/decryption model. (b) Encrypted text by different level of noise within the memristor crossbar. Each column is a BHV and each letter (A, B, C, D and E) is encoded 200 times. Optimal model is achieved when both noise and decryption accuracy are high.(c) Decryption performance of models with various dimension multipliers and crossbar noise level. Grid search on 10 dimensional secret key models with 0.05 P_on and 0.05 P_off . ‚ÄùGood‚Äù model (shaded) are those with decryption accuracy &gt;= 99.9% on test set. (d) Decryption accuracy vs conductance variability for selected models. Note that more noise means more security for the encoded BHV, while less dimension multiplier means less computation cost. (e) Power and complexity analysis of memristor crossbar implementation. (f) Time and complexity analysis.</p>

<h1 id="conclusion">Conclusion</h1>
<p>Overall, we demonstrate a novel cryptography algorithm designed specifically for memristor crossbar. In image encryption experiment, we verified our hypothesis using binary hypervectors to control crossbar noise levels. We then developed a stochastic text encryption system, and demonstrated near 100% decryption accuracy in the text decryption with selected crossbar models. This work is a proof of concept of how memristor crossbars with its non-ideal nature can be used to directly encrypt data, paving the foundations for future works in this direction.</p>

<h1 id="references">References</h1>
<p><a href="https://github.com/caixunshiren/HyperLock/blob/main/paper/Reference.pdf" target="_blank" rel="noopener noreferrer">Reference here</a></p>

  </article>

</div>


<script src="https://unpkg.com/typewriter-effect@latest/dist/core.js"></script>

<script type="text/javascript">
  var app = document.getElementById('typewriter');

  var typewriter = new Typewriter(app, {
    loop: false,
    delay: 75,
  });

  typewriter
    .start()
    .typeString('Projects')
</script>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        ¬© Copyright 2022 Jack Xun Cai. 
        ìÅπ‚ÄøìÅπ  ∞·µâ ∞    
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>
